# LLM_Paper_Reading



æœ¬æ–‡æ•´ç†äº†å¤§æ¨¡å‹æŠ€æœ¯ï¼ˆLLMï¼‰ç›®å‰å‘å±•å†ç¨‹ä¸Šæœ€é‡è¦çš„100+è®ºæ–‡

å…¶ä¸­ç¬¬ä¸€åˆ—çš„ğŸŒŸè¡¨ç¤ºè®ºæ–‡é‡è¦ç¨‹åº¦ï¼Œæ˜Ÿçº§è¶Šé«˜è¡¨æ˜è¶Šé‡è¦ã€‚

æœ¬æ–‡ä»åœ¨ç»§ç»­æ›´æ–°ä¸­ï¼Œå½“å‰æ›´æ–°æ—¶é—´2023/08/20

1. # OpenAI/Google åŸºç¡€è¯­â¾”â¼¤æ¨¡å‹

| **ID** | **Paper**                                                    | **Introduction**                                             |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡âœ¡âœ¡   | [Improving Language Understanding by Generative Pre-Training](https://www.mikecaptain.com/resources/pdf/GPT-1.pdf) | Open AI GPTåŸå§‹è®ºâ½‚æå‡ºäº†è§£ç å™¨æ¶æ„ï¼Œä»¥åŠä½¿ç”¨ä¸‹ä¸€ä¸ªå•è¯é¢„æµ‹è¿›è¡Œé¢„è®­ç»ƒçš„æ–¹æ³• |
| 2âœ¡âœ¡âœ¡   | [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) | Open AI GPT2åŸå§‹è®ºâ½‚GPT-2å’Œåç»­çš„GPT-3è®ºæ–‡è¯´æ˜äº†LLMèƒ½å¤Ÿè¿›è¡Œé›¶æ ·æœ¬ï¼ˆZero-shotï¼‰å’Œå°‘æ ·æœ¬å­¦ä¹ ï¼ˆFew-shotï¼‰ï¼ŒæŒ‡å‡ºäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„**æ¶Œç°èƒ½åŠ›** |
| 3âœ¡     | [Emergent Abilities of Large Language Models](https://arxiv.org/abs/2206.07682) | Google 22å¹´8â½‰ä»½ï¼Œæ¢è®¨â¼¤è¯­â¾”æ¨¡å‹çš„æ¶Œç°èƒ½â¼’                   |
| 4âœ¡âœ¡âœ¡âœ¡âœ¡ | [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165) | Open AI **GPT3åŸå§‹è®ºâ½‚**GPT-3ä»ç„¶æ˜¯è®­ç»ƒå½“ä¸‹å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ChatGPTï¼‰çš„å¸¸ç”¨åŸºçº¿å’ŒåŸºç¡€æ¨¡å‹ |
| 5âœ¡âœ¡âœ¡âœ¡  | [Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155) | **Open** **AI** **InstructGPTåŸå§‹è®ºâ½‚**ï¼Œä¹Ÿè¢«ç§°ä¸ºæè¿°ChatGPTèƒŒåæƒ³æ³•çš„è®ºæ–‡ç ”ç©¶äººå‘˜ä½¿ç”¨äº†ä¸€ç§å¼ºåŒ–å­¦ä¹ æœºåˆ¶ï¼Œå…¶ä¸­åŒ…æ‹¬äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆRLHFï¼‰ç ”ç©¶äººå‘˜ä»é¢„è®­ç»ƒçš„GPT-3åŸºç¡€æ¨¡å‹å¼€å§‹ï¼Œä½¿ç”¨ç›‘ç£å­¦ä¹ å¯¹äººç±»ç”Ÿæˆçš„æç¤ºä¸æ¨¡å‹å›å¤è¿›è¡Œè¿›ä¸€æ­¥å¾®è°ƒï¼›ç„¶åè¦æ±‚äººç±»å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œæ’åï¼Œä»¥è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼›æœ€åä½¿ç”¨å¥–åŠ±æ¨¡å‹é€šè¿‡PPOä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥æ›´æ–°é¢„è®­ç»ƒå’Œå¾®è°ƒçš„GPT-3æ¨¡å‹ã€‚ |
| 6      | [Evaluating Large Language Models Trained on Code](https://arxiv.org/pdf/2107.03374) | CodexåŸå§‹è®ºâ½‚                                                |
| 7âœ¡     | [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) | Google T5æ¨¡å‹ï¼ŒåŒºåˆ«äºBERTçš„ç¼–ç å™¨æ¶æ„ä¸GPTçš„è§£ç å™¨æ¶æ„ï¼ŒT5æ˜¯transformerçš„encoder-decoderæ¶æ„ï¼Œè¿™æ˜¯[è§£è¯»ä¹‹â¼€ ](https://zhuanlan.zhihu.com/p/88438851) |
| 8âœ¡     | [GPT-4 Technical Report](https://arxiv.org/pdf/2303.08774)   | GPT4çš„æŠ€æœ¯æŠ¥å‘Šï¼Œå¢åŠ äº†å¤šæ¨¡æ€èƒ½â¼’                             |

1. # LLMçš„å…³é”®æŠ€æœ¯ï¼š

**æ ¸å¿ƒåŸºçŸ³, The Beganing of Story.**

| **ID** | **Paper**                                                    | **Introduction**                                             |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡âœ¡âœ¡âœ¡âœ¡ | [Attention Is All You Need](https://arxiv.org/pdf/1706.03762) | TransformeråŸå§‹è®ºâ½‚æå‡ºäº†ç”±ç¼–ç å™¨å’Œè§£ç å™¨éƒ¨åˆ†ç»„æˆçš„åŸå§‹Transformeræ¶æ„ï¼Œå¹¶ä¸”æ–‡ä¸­æå‡ºçš„æ¦‚å¿µï¼Œå¦‚ç¼©æ”¾ç‚¹ç§¯ï¼ˆscale dot productï¼‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¤šå¤´æ³¨æ„å—ã€ä½ç½®è¾“å…¥ç¼–ç ç­‰ |

1. ## ICL

"in context learning"ï¼ˆä¸Šä¸‹æ–‡å­¦ä¹ ï¼‰æ˜¯æŒ‡åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ç¯å¢ƒä¸­å­¦ä¹ çš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚å®ƒè€ƒè™‘åˆ°æ–‡æœ¬ã€è¯­éŸ³ã€å›¾åƒã€è§†é¢‘ç­‰æ•°æ®çš„ä¸Šä¸‹æ–‡ç¯å¢ƒï¼Œä»¥åŠæ•°æ®ä¹‹é—´çš„å…³ç³»å’Œä¸Šä¸‹æ–‡ä¿¡æ¯çš„å½±å“ã€‚åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œå­¦ä¹ ç®—æ³•ä¼šåˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥æé«˜é¢„æµ‹å’Œåˆ†ç±»çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ å¯ä»¥å¸®åŠ©æœºå™¨å­¦ä¹ ç®—æ³•æ›´å¥½åœ°ç†è§£ä¸€ä¸ªå¥å­ä¸­çš„è¯è¯­å«ä¹‰å’Œå…³ç³»ã€‚

åœ¨in-context learningä¸­ï¼Œæ¨¡å‹ä¸æ ¹æ®ä¸‹æ¸¸ä»»åŠ¡è°ƒæ•´å‚æ•°ï¼Œè€Œæ˜¯å°†ä¸‹æ¸¸ä»»åŠ¡çš„è¾“å…¥è¾“å‡ºæ¥èµ·æ¥ä¹‹åä½œä¸ºpromptï¼Œå¼•å¯¼æ¨¡å‹æ ¹æ®æµ‹è¯•é›†çš„è¾“å…¥ç”Ÿæˆé¢„æµ‹ç»“æœã€‚è¯¥æ–¹æ³•çš„è¡¨ç°å¯ä»¥å¤§å¹…è¶…è¶Šé›¶ç›‘ç£å­¦ä¹ ï¼Œå¹¶ç»™å¤§æ¨¡å‹é«˜æ•ˆè¿ç”¨æä¾›äº†æ–°çš„æ€è·¯ã€‚

in-context learningå­¦ä¹ çš„å¹¶ä¸æ˜¯è¾“å…¥ä¸æ ‡æ³¨ä¹‹é—´çš„å…³è”ï¼Œè€Œæ˜¯é€šè¿‡å±•ç¤ºæ•°æ®å½¢å¼ï¼Œæ¥æ¿€æ´»é¢„è®­ç»ƒæ¨¡å‹çš„èƒ½åŠ›ã€‚ä¹Ÿå°±æ˜¯æç¤ºä¸­çš„ç¤ºä¾‹ä½¿æ¨¡å‹å¯ä»¥è¿›å…¥ç›¸åº”çš„ä»»åŠ¡æ¨¡å¼ï¼Œç„¶åæ‰§è¡Œä»»åŠ¡ã€‚

| **ID** | **Paper**                                                    | **Introduction**                                             |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡âœ¡âœ¡   | [A Survey on In-context Learning](https://arxiv.org/pdf/2301.00234) | ICL ç»¼è¿° **[Paper List for In-context Learning](https://github.com/dqxiu/ICL_PaperList)**i[n-context learning ç ”ç©¶æ¢³ç†ï¼š](https://zhuanlan.zhihu.com/p/583028638)[In-Context Learningåˆ°åº•æœ‰æ²¡æœ‰Learningï¼Ÿ](https://zhuanlan.zhihu.com/p/626292035) |
| 2âœ¡     | [Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?](https://arxiv.org/pdf/2202.12837) | å½“æŸäº›æ ‡ç­¾é”™è¯¯æ—¶ï¼Œæ¨¡å‹ä»ç„¶å¯ä»¥åšå‡ºæ­£ç¡®çš„é¢„æµ‹ã€‚è¿™è¡¨æ˜æ¨¡å‹æ›´å—æç¤ºçš„ [æ ¼å¼] å½±å“ï¼Œè€Œä¸æ˜¯æç¤ºçš„ [æ„ä¹‰] ã€‚ä½œè€…Sewonå¯¹è¿™éƒ¨åˆ†å†…å®¹è¿˜åšäº†å…¶ä»–ç ”ç©¶[Noisy Channel Language Model Prompting for Few-Shot Text Classification ](https://arxiv.org/pdf/2108.04106.pdf)[MetaICL: Learning to Learn In Context](https://arxiv.org/pdf/2110.15943.pdf) |
| 3âœ¡     | [Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers](https://arxiv.org/abs/2212.10559) | è¿™ç¯‡â½‚ç« åˆ™å°†ICLçœ‹ä½œæ˜¯â¼€ç§éšå¼çš„Fine-tuningï¼Œä»£ç åœ°å€ï¼šhttps://github.com/microsoft/LMOps[è®ºâ½‚çš„è§£è¯»ä¹‹â¼€ï¼šhttps://mp.weixin.qq.com/s/sTTRl7QPyFDYVw4Jwzn9dQ](https://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&mid=2247508429&idx=1&sn=aed7acb81b941db32cccede3c69b7350&scene=21#wechat_redirect) |
| 4âœ¡     | [Meta-learning via Language Model In-context Tuning](https://arxiv.org/abs/2110.07814) | å°†å…ƒå­¦ä¹ å¼•å…¥åˆ°In-Context Learningä¸­                          |
| 5âœ¡     | [WHAT LEARNING ALGORITHM IS IN-CONTEXT LEARNING? INVESTIGATIONS WITH LINEAR MODELS](https://arxiv.org/pdf/2211.15661.pdf) | ç¥ç»åºåˆ—æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯è½¬åŒ–å™¨ï¼Œè¡¨ç°å‡ºæ˜¾è‘—çš„è¯­å¢ƒä¸­å­¦ä¹ çš„èƒ½åŠ›     |
| 5âœ¡âœ¡âœ¡âœ¡  | [Finetuned Language Models Are Zero-Shot Learners](https://arxiv.org/pdf/2109.01652) | 21å¹´9â½‰ï¼ŒGoogleæå‡ºFLANâ¼¤æ¨¡å‹ï¼Œæå‡º**Instruct Learning**     |
| 6âœ¡âœ¡    | [The Flan Collection: Designing Data and Methods for Effective Instruction Tuning](https://arxiv.org/pdf/2301.13688.pdf) | è°·æ­Œä»‹ç»å¤§æ¨¡å‹æŒ‡ä»¤è°ƒä¼˜çš„ç›¸å…³å·¥ä½œï¼Œ[è§£è¯»](https://zhuanlan.zhihu.com/p/633346577) |
| 7âœ¡âœ¡âœ¡âœ¡  | [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf) | CMU ç›¸å…³èµ„æº http://pretrain.nlpedia.ai/NLP çš„èŒƒå¼æ¼”è¿›å†ç¨‹å¤§ä½“ç»å†äº†è¿™æ ·å››ä¸ªé˜¶æ®µï¼šç‰¹å¾å·¥ç¨‹â€”>æ·±åº¦å­¦ä¹ â€”>é¢„è®­ç»ƒ+ç²¾è°ƒâ€”>Prompt**Prompt** æ˜¯ç ”ç©¶è€…ä»¬ä¸ºäº†ä¸‹æ¸¸ä»»åŠ¡è®¾è®¡å‡ºæ¥çš„ä¸€ç§è¾“å…¥å½¢å¼æˆ–æ¨¡æ¿ï¼Œå®ƒèƒ½å¤Ÿå¸®åŠ©é¢„è®­ç»ƒæ¨¡å‹â€œå›å¿†â€èµ·è‡ªå·±åœ¨é¢„è®­ç»ƒæ—¶â€œå­¦ä¹ â€åˆ°çš„ä¸œè¥¿ã€‚æœ¬æ–‡è°ƒæŸ¥å¹¶ç»„ç»‡äº†NLPä¸­çš„ä¸€ä¸ªæ–°èŒƒå¼çš„ç ”ç©¶å·¥ä½œï¼šâ€œåŸºäº prompt çš„å­¦ä¹ â€ã€‚ |
| 8âœ¡âœ¡    | [SELF-INSTRUCT: Aligning Language Models with Self-Generated Instructions](https://arxiv.org/pdf/2212.10560.pdf) | ä»£ç åœ°å€ https://github.com/yizhongw/self-instructè§£è¯»1 https://zhuanlan.zhihu.com/p/614916562è§£è¯»2 https://zhuanlan.zhihu.com/p/6115704013â½‰ä¸­æ—¬ï¼Œæ–¯å¦ç¦å‘å¸ƒAlpacaï¼šåªèŠ±100ç¾å…ƒï¼Œâ¼ˆâ¼ˆéƒ½å¯å¾®è°ƒMetaå®¶70äº¿å‚æ•°çš„LLaMAâ¼¤æ¨¡å‹â½½æ–¯å¦ç¦å›¢é˜Ÿå¾®è°ƒLLaMAçš„â½…æ³•ï¼Œä¾¿æ˜¯æ¥â¾ƒåç››é¡¿â¼¤å­¦Yizhong Wangç­‰å»å¹´åº•æå‡ºçš„è¿™ä¸ªSelf-Instructå…·ä½“â½½â¾”ï¼Œè®ºâ½‚ä¸­æå‡ºï¼Œâ¾¸å…ˆä»â¾ƒâ½£æˆæŒ‡ä»¤ç§â¼¦é›†ä¸­çš„175ä¸ªâ¼ˆâ¼¯ç¼–å†™çš„ã€ŒæŒ‡ä»¤-è¾“å‡ºã€å¯¹å¼€å§‹ï¼Œç„¶åï¼Œæç¤ºtext-davinci-003ä½¿â½¤ç§â¼¦é›†ä½œä¸ºä¸Šä¸‹â½‚ç¤ºä¾‹æ¥â½£æˆæ›´å¤šæŒ‡ä»¤â½½æ–¯å¦ç¦ç‰ˆAlpacaï¼Œå°±æ˜¯èŠ±äº†ä¸åˆ°500ç¾å…ƒä½¿â½¤OpenAI APIâ½£æˆäº†5.2ä¸‡ä¸ªè¿™æ ·çš„ç¤ºä¾‹å¾®è°ƒLLaMAæå‡ºæ¥çš„ |
| 9âœ¡     | [Offsite-Tuning: Transfer Learning without Full Model](https://arxiv.org/pdf/2302.04870.pdf) |                                                              |

## 2.2CoT

äººç±»åœ¨é‡åˆ°ä¸€ç³»åˆ—é—®é¢˜æ—¶æ‰€äº§ç”Ÿçš„æ¨ç†æ­¥éª¤ï¼Œè€Œå®ƒä»¬çš„è¡¨ç°å½¢å¼å°±æ˜¯ä¸€ç³»åˆ—çš„çŸ­å¥å­ï¼ˆæ¯”å¦‚è¯´åœ¨èƒŒæ™¯ä»‹ç»ä¸­æ‰€æåˆ°çš„é‡åˆ°æ•°å­¦é—®é¢˜æ—¶æ‰€äº§ç”Ÿçš„ä¸­é—´æ¨ç†æ­¥éª¤ï¼‰

| **ID** | **Paper**                                                    | **Introduction**                                             |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡âœ¡âœ¡   | [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://paperswithcode.com/paper/chain-of-thought-prompting-elicits-reasoning) | CoTåŸå§‹è®ºâ½‚ï¼Œå°è¯äº†instructGPTä»22å¹´1â½‰ä»½ä¹‹å‰ å°±å¼€å§‹è¿­ä»£äº†   |
| 2âœ¡âœ¡âœ¡   | [Large Language Models are Zero-Shot Reasoners](https://openreview.net/pdf?id=e2TBb5y0yFf) | æ¥â¾ƒä¸œäº¬â¼¤å­¦å’Œâ¾•æ­Œçš„â¼¯ä½œï¼Œå…³äºé¢„è®­ç»ƒâ¼¤å‹è¯­â¾”æ¨¡å‹çš„æ¨ç†èƒ½â¼’çš„æ¢ç©¶ï¼Œchain of thoughtï¼ˆCoTï¼‰èƒ½å¤Ÿæ˜¾è‘—çš„æå‡å¤§æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè€Œç°æœ‰ç ”ç©¶å·¥ä½œå¤§éƒ½ç ”ç©¶çš„æ˜¯few shotè®¾ç½®ä¸‹CoTï¼Œå› æ­¤æœ¬æ–‡ä¸»è¦ç ”ç©¶zero shotè®¾ç½®ä¸‹çš„å¤§æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚[è§£è¯»](https://zhuanlan.zhihu.com/p/610535012)ã€‚â€œLet's think step by stepâ€çš„æ¢—å³æ¥æºäºæ­¤ç¯‡è®ºâ½‚ |
| 3âœ¡     | [Automatic Chain of thought Prompting in Large Language Models](https://arxiv.org/pdf/2210.03493.pdf) | auto-CoT                                                     |
| 4âœ¡     | [Multimodal Chain-of-Thought Reasoning in Language Models](https://arxiv.org/abs/2302.00923) | 23å¹´2â½‰ï¼Œäºšâ»¢é€Šçš„ç ”ç©¶è€…åœ¨è¿™ç¯‡è®ºâ½‚â¾¥æå‡ºäº†åŸºäºå¤šæ¨¡æ€æ€ç»´é“¾æŠ€æœ¯æ”¹è¿›è¯­â¾”æ¨¡å‹å¤æ‚æ¨ç†èƒ½â¼’çš„æ€æƒ³ |

## 2.3RLHF

| **ID** | **Paper**                                                    | **Introduction**                                             |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡âœ¡âœ¡âœ¡âœ¡ | [Fine-Tuning Language Models from Human Preferences](https://arxiv.org/pdf/1909.08593.pdf) | RLHFåŸå§‹è®ºâ½‚ [è§£è¯»](https://huggingface.co/blog/zh/rlhf) ä»£ç  https://github.com/openai/lm-human-preferencesç›¸å…³è®ºæ–‡åŒ…æ‹¬åœ¨ç°æœ‰ LM å‰çš„ RLHF è¿›å±•å’ŒåŸºäºå½“å‰ LM çš„ RLHF å·¥ä½œï¼š[TAMER: Training an Agent Manually via Evaluative Reinforcement](https://www.cs.utexas.edu/~pstone/Papers/bib2html-links/ICDL08-knox.pdf) (Knox and Stone 2008)[Interactive Learning from Policy-Dependent Human Feedback](http://proceedings.mlr.press/v70/macglashan17a/macglashan17a.pdf) (MacGlashan et al. 2017)[Deep TAMER: Interactive Agent Shaping in High-Dimensional State Spaces](https://ojs.aaai.org/index.php/AAAI/article/view/11485)[Learning to summarize with human feedback](https://proceedings.neurips.cc/paper/2020/hash/1f89885d556929e98d3ef9b86448f951-Abstract.html) (Stiennon et al., 2020)[Recursively Summarizing Books with Human Feedback](https://arxiv.org/abs/2109.10862) (OpenAI Alignment Team 2021)[WebGPT: Browser-assisted question-answering with human feedback](https://arxiv.org/abs/2112.09332) (OpenAI, 2021)GopherCite: [Teaching language models to support answers with verified quotes](https://www.deepmind.com/publications/gophercite-teaching-language-models-to-support-answers-with-verified-quotes) (Menick et al. 2022)Sparrow: [Improving alignment of dialogue agents via targeted human judgements](https://arxiv.org/abs/2209.14375) (Glaese et al. 2022)[ChatGPT: Optimizing Language Models for Dialogue](https://openai.com/blog/chatgpt/) (OpenAI 2022)[Scaling Laws for Reward Model Overoptimization](https://arxiv.org/abs/2210.10760) (Gao et al. 2022)[Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2204.05862) (Anthropic, 2022)[Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned](https://arxiv.org/abs/2209.07858) (Ganguli et al. 2022)[Dynamic Planning in Open-Ended Dialogue using Reinforcement Learning](https://arxiv.org/abs/2208.02294) (Cohen at al. 2022)[Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization](https://arxiv.org/abs/2210.01241) (Ramamurthy and Ammanabrolu et al. 2022)[Kojima et al. 2021](https://arxiv.org/abs/2108.04812)[Suhr and Artzi 2022](https://arxiv.org/abs/2212.09710)[Sokolov et al. 2016](https://arxiv.org/abs/1601.04468), [Gao et al. 2022](https://arxiv.org/abs/2203.10079)[Ranzato et al. 2015](https://arxiv.org/abs/1511.06732)[Bahdanau et al. 2016](https://arxiv.org/abs/1607.07086)[Nguyen et al. 2017](https://arxiv.org/abs/1707.07402) |
| 2âœ¡âœ¡    | [Deep Reinforcement Learning from Human Preferences](https://arxiv.org/pdf/1706.03741.pdf) | æœ€æ—©æå‡ºçš„RLHFæ–¹æ³•                                           |
| 3âœ¡     | [Trust Region Policy Optimization](https://arxiv.org/abs/1502.05477) | TRPOè®ºæ–‡ï¼Œæ—©äºPPOæ–¹æ³•ï¼Œ[è§£è¯»](https://zhuanlan.zhihu.com/p/292361775) |
| 4âœ¡     | [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783.pdf) | å¼•å…¥äº†ç­–ç•¥æ¢¯åº¦æ–¹æ³•ä½œä¸ºåŸºäºæ·±åº¦å­¦ä¹ çš„RLä¸­Qå­¦ä¹ çš„æ›¿ä»£æ–¹æ¡ˆã€‚    |
| 5âœ¡âœ¡    | [Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347) | 2017å¹´ï¼ŒOpenAIå‘å¸ƒçš„PPOåŸå§‹è®ºâ½‚æå‡ºäº†ä¸€ç§æ”¹è¿›çš„åŸºäºè¿‘ä¼¼ç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œæ¯”ä¸Šé¢çš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•æ›´å…·æ•°æ®æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚ |
| 6âœ¡     | [Fine-Tuning Language Models from Human Preferences ](https://arxiv.org/pdf/1909.08593.pdf) | è®ºæ–‡è¯´æ˜äº†PPOçš„æ¦‚å¿µå’Œå¯¹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å¥–åŠ±å­¦ä¹ ï¼ŒåŒ…æ‹¬KLæ­£åˆ™åŒ–ï¼Œä»¥é˜²æ­¢ç­–ç•¥ä¸è‡ªç„¶è¯­è¨€åç¦»å¤ªè¿œ |
| 7âœ¡     | [Learning to Summarize from Human Feedback](https://arxiv.org/pdf/2009.01325.pdf) | è®ºæ–‡æå‡ºäº†å¸¸ç”¨çš„RLHFä¸‰æ­¥ç¨‹åºï¼šé¢„è®­ç»ƒGPT-3ä»¥æœ‰ç›‘ç£çš„æ–¹å¼è¿›è¡Œå¾®è°ƒåŒæ ·ä»¥æœ‰ç›‘ç£çš„æ–¹å¼è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œç„¶åä½¿ç”¨å…·æœ‰é‚»è¿‘ç­–ç•¥ä¼˜åŒ–çš„å¥–åŠ±æ¨¡å‹æ¥è®­ç»ƒå¾®è°ƒæ¨¡å‹ã€‚è®ºæ–‡è¿˜è¡¨æ˜ï¼Œä¸å¸¸è§„æœ‰ç›‘ç£å­¦ä¹ ç›¸æ¯”ï¼Œå…·æœ‰è¿‘ä¼¼ç­–ç•¥ä¼˜åŒ–çš„å¼ºåŒ–å­¦ä¹ å¯ä»¥äº§ç”Ÿæ›´å¥½çš„æ¨¡å‹ã€‚ |
| 8âœ¡     | [Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf) | å¾®è°ƒPaLM-540B(2022å¹´10â½‰)ä»ä¸‰ä¸ªâ½…â¾¯æ”¹å˜æŒ‡ä»¤å¾®è°ƒï¼Œâ¼€æ˜¯æ”¹å˜æ¨¡å‹å‚æ•°ï¼Œæå‡åˆ°äº†540Bï¼Œâ¼†æ˜¯å¢åŠ åˆ°äº†1836ä¸ªå¾®è°ƒä»»åŠ¡ï¼Œä¸‰æ˜¯åŠ ä¸ŠChain of thoughtå¾®è°ƒçš„æ•°æ® |
|        | [Self-Instruct: Aligning Language Model with Self Generated Instruction](https://arxiv.org/pdf/2212.10560.pdf) | æŒ‡ä»¤å¾®è°ƒæ˜¯ä»GPT-3ä¹‹ç±»çš„é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹å‘å±•åˆ°ChatGPTç±»æ›´å¼ºå¤§è¯­è¨€æ¨¡å‹çš„å…³é”®æŠ€æœ¯ã€‚Self-Instructæ˜¯ä¸€ç§å‡ ä¹æ— éœ€æ ‡æ³¨ï¼Œå³å¯å°†é¢„è®­ç»ƒçš„LLMä¸æŒ‡ä»¤å¯¹é½çš„æ–¹æ³•ï¼Œæ€»å…±åŒ…æ‹¬4ä¸ªæ­¥éª¤ï¼šç”¨ä¸€ç»„äººå·¥ç¼–å†™çš„æŒ‡ä»¤å’Œæ ·æœ¬æŒ‡ä»¤ä½œä¸ºç§å­ä»»åŠ¡æ± ã€‚ä½¿ç”¨é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-3ï¼‰æ¥ç¡®å®šä»»åŠ¡ç±»åˆ«ã€‚ç»™å®šæ–°æŒ‡ä»¤ï¼Œè®©é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ç”Ÿæˆå›å¤ã€‚åœ¨å°†å›å¤æ·»åŠ åˆ°ä»»åŠ¡æ± ä¹‹å‰ï¼Œæ”¶é›†ã€ä¿®å‰ªå’Œç­›é€‰è¿™äº›å“åº”ã€‚åœ¨å®è·µä¸­ï¼Œæ•´ä¸ªè¿‡ç¨‹å¯ä»¥åŸºäºROUGEæ¥è¯„åˆ†ï¼Œå¯ä»¥è®¤ä¸ºSelf-Instruct-finetuned LLMçš„æ€§èƒ½ä¼˜äºGPT-3åŸºç¡€LLMï¼Œå¹¶ä¸”å¯ä»¥ä¸åœ¨å¤§å‹äººç±»ç¼–å†™çš„æŒ‡ä»¤é›†ä¸Šé¢„è®­ç»ƒçš„LLMç«äº‰ï¼Œself-instructä¹Ÿå¯ä»¥ä½¿å·²ç»æ ¹æ®äººç±»æŒ‡ä»¤è¿›è¡Œå¾®è°ƒçš„LLMå—ç›Šã€‚å½“ç„¶ï¼Œè¯„ä¼°è¯­è¨€æ¨¡å‹çš„é»„é‡‘æ ‡å‡†æ˜¯è¯¢é—®äººç±»è¯„åˆ†å‘˜ã€‚åŸºäºäººç±»è¯„ä¼°ï¼ŒSelf-Instructä¼˜äºåŸºæœ¬LLMå’Œä»¥ç›‘ç£æ–¹å¼åœ¨äººç±»æŒ‡ä»¤æ•°æ®é›†ä¸Šè®­ç»ƒçš„LLMï¼ˆSuperNIï¼ŒT0 Trainerï¼‰ï¼Œä½†æœ‰è¶£çš„æ˜¯ï¼ŒSelf-Instructå¹¶æ²¡æœ‰ä¼˜äºé€šè¿‡äººå·¥åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰è®­ç»ƒçš„æ–¹æ³•ã€‚ |
|        | [Illustrating Reinforcement Learning from Human Feedback](https://huggingface.co/blog/rlhf) | huggingfaceè§£è¯»RHLFç®—æ³•                                      |
|        | [Augmenting Reinforcement Learning with Human Feedback](https://www.cs.utexas.edu/users/ai-lab/pubs/ICML_IL11-knox.pdf) | RHLFç®—æ³•è®ºæ–‡                                                 |

## 2.4 PEFT

é«˜æ•ˆå‚æ•°å¾®è°ƒ(Parameter-Efficient Fine-Tuning)

| **ID** | **Paper**                                                    | **Introduction**                                             |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡âœ¡âœ¡âœ¡  | [Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2303.15647.pdf) | ç»¼è¿°å›é¡¾äº†40å¤šç¯‡å…³äºå‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼ŒåŒ…æ‹¬prefixè°ƒæ•´ã€adapterå’ŒLoRAç­‰ã€‚[Parameter-Efficient Fine-Tuning (PEFT)](https://github.com/huggingface/peft) |
| 2âœ¡âœ¡âœ¡âœ¡âœ¡ | [LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2106.09685.pdf) | LoRa å¾®è°ƒæ–¹æ³•è®ºæ–‡åœ¨å¤§å‹æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹å±•ç°å‡ºäº†æ¶Œç°èƒ½åŠ›ï¼Œä¸è¿‡å¦‚æœæƒ³æé«˜Transformeråœ¨ç‰¹å®šé¢†åŸŸæ•°æ®å’Œç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œé‚£ä¹ˆå°±éœ€è¦å¯¹Transformerè¿›è¡Œå¾®è°ƒ(SFT)ã€‚ä½ç§©è‡ªé€‚åº”ï¼ˆLoRAï¼‰æ˜¯ä¸€ç§å‚æ•°é«˜æ•ˆï¼ˆparameter-efficient-PEFTï¼‰çš„æ–¹å¼æ¥å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç›¸æ¯”å…¶ä»–æ–¹æ³•ï¼ŒLoRAæ—¢ä¼˜é›…åˆéå¸¸é€šç”¨ï¼Œå¯ä»¥åº”ç”¨äºå…¶ä»–ç±»å‹çš„æ¨¡å‹ã€‚è™½ç„¶é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡åœ¨é¢„è®­ç»ƒä»»åŠ¡ä¸Šå…·æœ‰æ»¡ç§©ï¼Œä½†LoRAä½œè€…æŒ‡å‡ºï¼Œé¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€‚åº”æ–°ä»»åŠ¡æ—¶å…·æœ‰è¾ƒä½çš„ã€Œå†…åœ¨ç»´åº¦ã€ã€‚å› æ­¤ï¼ŒLoRAèƒŒåçš„ä¸»è¦æ€æƒ³æ˜¯å°†æƒé‡å˜åŒ–Î”Wåˆ†è§£ä¸ºæ›´ä½ç§©çš„è¡¨ç¤ºï¼Œå³æ›´é«˜æ•ˆçš„å‚æ•°ã€‚ |
| 3âœ¡âœ¡âœ¡   | [Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf) | Prefix-tuning å¾®è°ƒæ–¹æ³•è®ºæ–‡                                   |
| 4âœ¡âœ¡    | [GPT Understands, Too](https://arxiv.org/pdf/2103.10385)     | p-tuning V1è®ºâ½‚                                              |
| 5âœ¡âœ¡âœ¡   | [P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](https://arxiv.org/pdf/2110.07602.pdf) | p-tuning V2è®ºâ½‚                                              |
| 6âœ¡âœ¡âœ¡   | [The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf) | Prompt Tuning                                                |
|        |                                                              |                                                              |

## 2.5 Embedding/ä½ç½®ç¼–ç /æ¿€æ´»å‡½æ•°/attentionåŠ é€Ÿ

| **ID** | **Paper**                                                    | **Introduction**                                             |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡     | [Distributed Representations of Sentences and Documents](https://arxiv.org/pdf/1405.4053.pdf) | Mikolovâ¾¸æ¬¡æå‡º Word2vec                                     |
| 2âœ¡     | [Efficient estimation of word representations in vector space](https://arxiv.org/pdf/1301.3781.pdf) | Mikolovä¸“â»”è®²è®­ç»ƒ Word2vec ä¸­çš„ä¸¤ä¸ªtrickï¼šhierarchical softmax å’Œ negative sampling |
| 3âœ¡     | [word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method](https://arxiv.org/pdf/1402.3722.pdf) | Yoav Goldbergå…³äºword2vecçš„è®ºâ½‚ï¼Œå¯¹ negative-sampling çš„å…¬å¼æ¨å¯¼â¾®å¸¸å®Œå¤‡ |
| 4âœ¡     | [word2vec Parameter Learning Explained](https://arxiv.org/pdf/1411.2738.pdf) | Xin Rongå…³äºword2vecçš„è®ºâ½‚ï¼Œâ¾®å¸¸ä¸é”™                         |
| 5âœ¡âœ¡    | [ROFORMER: ENHANCED TRANSFORMER WITH ROTARY POSITION EMBEDDING](https://arxiv.org/pdf/2104.09864.pdf) | æ—‹è½¬ä½ç½®åµŒâ¼Š(RoPE)è®ºâ½‚ï¼Œ[è¿™æ˜¯è‹å‰‘æ—æœ¬â¼ˆå¯¹å®ƒçš„è§£è¯»](https://kexue.fm/archives/8265) |
| 6âœ¡âœ¡    | [Linearized Relative Positional Encoding](https://openreview.net/pdf?id=xoLyps2qWc) | ç»Ÿâ¼€äº†é€‚â½¤äºlinear transformerçš„ç›¸å¯¹ ä½ç½®ç¼–ç                 |
| 7âœ¡âœ¡âœ¡   | [SEARCHING FOR ACTIVATION FUNCTIONS](https://arxiv.org/pdf/1710.05941.pdf) | SwiGLUçš„åŸå§‹è®ºâ½‚                                             |
| 8âœ¡     | [The Natural Language Decathlon: Multitask Learning as Question Answering](https://arxiv.org/pdf/1806.08730.pdf) | GPT-1ã€GPT-2è®ºâ½‚çš„å¼•â½¤â½‚çŒ®ï¼ŒSalesforceå‘è¡¨çš„â¼€ç¯‡â½‚ç« ï¼Œå†™å‡ºäº†å¤šä»»åŠ¡å•æ¨¡å‹çš„æ ¹æœ¬æ€æƒ³ |
| 9âœ¡âœ¡    | [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](https://arxiv.org/pdf/1910.02054.pdf) | ZeROæ˜¯å¾®è½¯deepspeedçš„æ ¸â¼¼ï¼Œè¿™æ˜¯å…³äºZeROçš„[è§£è¯»ä¹‹â¼€](https://basicv8vc.github.io/posts/zero/) |
| 10âœ¡    | [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/pdf/2104.04473.pdf) | Megatron-LM è®ºâ½‚åŸå§‹è®ºâ½‚å¯¹ç›¸å…³æŠ€æœ¯çš„è§£è¯»ï¼š[åƒäº¿å‚æ•°å¼€æºâ¼¤æ¨¡å‹ BLOOM èƒŒåçš„æŠ€æœ¯](https://huggingface.co/blog/zh/bloom-megatron-deepspeed) |
| 11âœ¡    | [Training Deep Nets with Sublinear Memory Cost](https://arxiv.org/pdf/1604.06174.pdf) | æå‡ºäº†ä¸€ç§å‡å°‘æ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒæ—¶å†…å­˜æ¶ˆè€—çš„ç³»ç»Ÿæ€§æ–¹æ³•ã€‚       |
| 12âœ¡âœ¡   | [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/pdf/2205.14135.pdf) | Flash attention è¿™æ˜¯å…¶[è§£è¯»ä¹‹â¼€](https://zhuanlan.zhihu.com/p/639228219)è™½ç„¶å¤§å¤šæ•°transformerè®ºæ–‡éƒ½æ²¡æœ‰æ›¿æ¢åŸå§‹çš„ç¼©æ”¾ç‚¹ç§¯æœºåˆ¶æ¥æ”¹è¿›è‡ªæ³¨æ„åŠ›ï¼Œä½†FlashAttentionæ˜¯å…¶ä¸­æœ€å¸¸å¼•ç”¨çš„ä¸€ç§æœºåˆ¶ã€‚ |
| 13âœ¡    | [Fast Transformer Decoding: One Write-Head is All You Need](https://arxiv.org/pdf/1911.02150.pdf) | Muti Query Attentionè®ºâ½‚ï¼ŒMQA æ˜¯ 19 å¹´æå‡ºçš„â¼€ç§æ–°çš„ Attention æœºåˆ¶ï¼Œå…¶èƒ½å¤Ÿåœ¨ä¿è¯æ¨¡å‹æ•ˆæœçš„åŒæ—¶åŠ å¿« decoder â½£æˆ token çš„é€Ÿåº¦ï¼Œè¿™æ˜¯å…¶[è§£è¯»ä¹‹â¼€](https://zhuanlan.zhihu.com/p/634236135) |
| 14âœ¡âœ¡   | [GQA: Training Generalized Multi-Query Transformer Models fromMulti-Head Checkpoints](https://arxiv.org/pdf/2305.13245.pdf) | GQALLaMA-2 ä½¿ç”¨äº†è¯¥æŠ€æœ¯æ¥åŠ é€Ÿ                                |
| 15âœ¡    | [Cramming: Training a Language Model on a Single GPU in One Day](https://arxiv.org/pdf/2212.14034.pdf) | åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œç ”ç©¶äººå‘˜ä½¿ç”¨å•ä¸ªGPUç”¨äº†24ä¸ªå°æ—¶è®­ç»ƒäº†ä¸€ä¸ªé®ç½©è¯­è¨€æ¨¡å‹/ç¼–ç å™¨é£æ ¼çš„è¯­è¨€æ¨¡å‹ï¼Œåœ¨å•ä¸ªGPUä¸Šè¿›è¡Œ24å°æ—¶ï¼Œç›¸æ¯”ä¹‹ä¸‹ï¼Œ2018å¹´BERTåˆšæå‡ºæ¥çš„æ—¶å€™ï¼Œåœ¨16ä¸ªTPUä¸Šè®­ç»ƒäº†å››å¤©ã€‚æœ‰è¶£çš„ç»“è®ºæ˜¯ï¼Œè™½ç„¶è¾ƒå°çš„æ¨¡å‹å…·æœ‰æ›´é«˜çš„ååé‡ï¼Œä½†å°æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡ä¹Ÿæ¯”è¾ƒä½ï¼Œæ‰€ä»¥è¾ƒå¤§çš„æ¨¡å‹ä¸éœ€è¦æ›´å¤šçš„è®­ç»ƒæ—¶é—´æ¥è¾¾åˆ°ç‰¹å®šçš„é¢„æµ‹æ€§èƒ½é˜ˆå€¼ã€‚ |
| 16âœ¡âœ¡   | [Scaling Language Models: Methods, Analysis & Insights from Training Gopher](https://arxiv.org/pdf/2112.11446.pdf) | Gopherè®ºæ–‡ä¸­æœ‰å¤§é‡çš„åˆ†ææ¥ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚ç ”ç©¶äººå‘˜åœ¨3000äº¿ä¸ªtokenä¸Šè®­ç»ƒäº†ä¸€ä¸ª80å±‚ã€2800äº¿å‚æ•°çš„æ¨¡å‹ï¼Œè¿˜æå‡ºäº†ä¸€äº›æ¶æ„ä¸Šçš„ä¿®æ”¹ï¼Œå¦‚ä½¿ç”¨RMSNormï¼ˆå‡æ–¹æ ¹å½’ä¸€åŒ–ï¼‰è€ŒéLayerNormï¼ˆå±‚å½’ä¸€åŒ–ï¼‰ã€‚LayerNormå’ŒRMSNorméƒ½ä¼˜äºBatchNormï¼Œå› ä¸ºå®ƒä»¬å¹¶ä¸ä¾èµ–äºbatch sizeï¼Œä¹Ÿä¸éœ€è¦åŒæ­¥ï¼Œå¯¹äºåœ¨batch sizeè¾ƒå°çš„åˆ†å¸ƒå¼è®¾ç½®ä¸­æ˜¯ä¸€ä¸ªä¼˜åŠ¿ï¼Œè€Œä¸”RMSNormé€šå¸¸è¢«è®¤ä¸ºå¯ä»¥ç¨³å®šæ›´æ·±å±‚æ¬¡æ¶æ„ä¸­çš„è®­ç»ƒã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦é‡ç‚¹æ˜¯ä¸åŒå°ºåº¦ï¼ˆsacleï¼‰æ¨¡å‹åœ¨ä»»åŠ¡æ€§èƒ½ä¸Šçš„åˆ†æã€‚å¯¹152ä¸ªä¸åŒä»»åŠ¡çš„è¯„ä¼°è¡¨æ˜ï¼Œå¢åŠ æ¨¡å‹å°ºå¯¸å¯¹ç†è§£ã€äº‹å®æ ¸æŸ¥å’Œæœ‰æ¯’è¯­è¨€è¯†åˆ«ç­‰ä»»åŠ¡çš„ç›Šå¤„æœ€å¤§ï¼Œè€Œä¸é€»è¾‘å’Œæ•°å­¦æ¨ç†ç›¸å…³çš„ä»»åŠ¡ä»æ¶æ„æ‰©å±•ä¸­å—ç›Šè¾ƒå°‘ã€‚ |
| 17âœ¡âœ¡   | [Training Compute-Optimal Large Language Models](https://arxiv.org/pdf/2203.15556.pdf) | è®ºæ–‡ä¸­å®šä¹‰äº†å¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒçš„çº¿æ€§ç¼©æ”¾å¾‹ï¼ˆlinear scaling lowï¼‰ï¼Œä¾‹å¦‚è™½ç„¶Chinchillaçš„å¤§å°åªæœ‰GPT-3çš„ä¸€åŠï¼Œä½†å®ƒçš„è¡¨ç°ä¼˜äºGPT-3ï¼Œå› ä¸ºå®ƒæ˜¯åœ¨1.4ä¸‡äº¿ï¼ˆè€Œä¸æ˜¯3000äº¿ï¼‰ä¸ªtokenä¸Šè®­ç»ƒçš„ã€‚æ¢å¥è¯è¯´ï¼Œè®­ç»ƒè¯­æ–™ä¸­tokençš„æ•°é‡ä¸æ¨¡å‹å¤§å°ä¸€æ ·é‡è¦ã€‚ |
| 18     | [Transformer-XL: Attentive language models beyond a fixed-length context](https://arxiv.org/pdf/1901.02860.pdf) |                                                              |

## 2.6 ç»¼è¿°åŠå…¶ä»–

| **ID** | **Paper**                                                    | **Introduction**                                             |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡âœ¡    | [Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper) | ResNetè®ºâ½‚è¿™æ˜¯[ææ²é’ˆå¯¹ResNetçš„è§£è¯»](https://www.bilibili.com/video/BV1P3411y7nn/?vd_source=0534c0954ddd3d4c4bd8113d31975f6a)ï¼Œå¦ è¿™æ˜¯æ[æ²é’ˆå¯¹â¼€äº›paperçš„è§£è¯»åˆ—è¡¨](https://github.com/mli/paper-reading) |
| 2âœ¡âœ¡    | [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf) | BERTè®ºæ–‡æå‡ºäº†é®ç½©è¯­è¨€å»ºæ¨¡(Mask LM)ï¼Œå¹¶ä¸”ä¸‹ä¸€å¥é¢„æµ‹ï¼ˆnext-sentence predictionï¼‰ä»ç„¶æ˜¯ä¸€ç§æœ‰å½±å“åŠ›çš„è§£ç å™¨æ¶æ„ï¼Œä¸è¿‡åç»­çš„RoberTaåˆ é™¤äº†ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡ï¼Œç®€åŒ–äº†é¢„è®­ç»ƒç›®æ ‡ã€‚ |
| 3âœ¡âœ¡    | [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/pdf/1910.13461.pdf) | BERTç±»è¯­è¨€æ¨¡å‹ä¸»è¦å…³æ³¨ç¼–ç å™¨ï¼Œé€šå¸¸æ˜¯é¢„æµ‹å»ºæ¨¡ä»»åŠ¡çš„é¦–é€‰ï¼Œè€ŒGPTç±»å‹çš„è§£ç å™¨é£æ ¼çš„è¯­è¨€æ¨¡å‹åœ¨æ–‡æœ¬ç”Ÿæˆæ–¹é¢æ›´å¥½ã€‚ä¸ºäº†åŒæ—¶åˆ©ç”¨äºŒè€…çš„ä¼˜åŠ¿ï¼ŒBARTè®ºæ–‡ç»“åˆäº†ç¼–ç å™¨å’Œè§£ç å™¨éƒ¨åˆ†ã€‚ |
| 4âœ¡âœ¡    | [Efficient Transformers: A Survey](https://arxiv.org/pdf/2009.06732.pdf) | ç»¼è¿°æŠ¥å‘Šï¼Œå…³äºæé«˜Transformeræ•ˆç‡çš„å„ç§æŠ€æœ¯-1ã€‚ä¸»è¦é’ˆå¯¹ä¸€ç±»X-formeræ¨¡å‹ï¼Œä¾‹å¦‚Reformer, Linformer, Performer, Longformerä¸ºä¾‹ï¼Œè¿™äº›å¯¹åŸç‰ˆTransformeråšäº†æ”¹è¿›ï¼Œæé«˜äº†å…¶è®¡ç®—å’Œå†…å­˜çš„æ•ˆç‡ã€‚ |
| 5âœ¡âœ¡    | [A Survey on Efficient Training of Transformers](https://arxiv.org/pdf/2302.01107.pdf) | ç»¼è¿°æŠ¥å‘Šï¼Œå…³äºæé«˜Transformeræ•ˆç‡çš„å„ç§æŠ€æœ¯ã€‚                |
| 6âœ¡âœ¡    | [Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond](https://arxiv.org/pdf/2304.13712.pdf) | ç»¼è¿°æŠ¥å‘Šï¼Œè¯´æ˜äº†ä¸åŒçš„æ¶æ„æ˜¯å¦‚ä½•æ¼”å˜çš„ï¼Œæä¾›äº†LLM family treeé™¤äº†è®¨è®ºBERTé£æ ¼çš„é®ç½©è¯­è¨€æ¨¡å‹ï¼ˆç¼–ç å™¨ï¼‰å’ŒGPTé£æ ¼çš„è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆè§£ç å™¨ï¼‰ä¹‹å¤–ï¼Œè¿˜æä¾›äº†å…³äºé¢„è®­ç»ƒå’Œå¾®è°ƒæ•°æ®çš„è®¨è®ºå’ŒæŒ‡å¯¼ã€‚ |
| 7âœ¡âœ¡    | [Unifying Large Language Models and Knowledge Graphs: A Roadmap](https://arxiv.org/pdf/2306.08302.pdf) | LLMä¸çŸ¥è¯†å›¾è°±çš„ç»“åˆå®æˆ˜                                      |
| 8âœ¡âœ¡    | [A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT](https://arxiv.org/pdf/2302.09419.pdf) | é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹çš„æ¼”å˜å²                                       |
| 9âœ¡âœ¡    | [Pre-Trained Models: Past, Present and Future](https://arxiv.org/pdf/2106.07139v3.pdf) | 21å¹´1â½‰åˆåœ¨CCFå¯æ™ºä¼šâ½€æŒä¸‹ï¼Œâ½‚ç»§è£ã€å”æ°å’Œâ»©âº çƒˆä¸‰ä½â½¼å¸ˆå¬é›†äº†ä»¥é¢„è®­ç»ƒæ¨¡å‹ä¸ºä¸»é¢˜çš„é—­â»”ç ”è®¨ä¼šï¼Œæ­¤å22ä½â½¼å¸ˆå’ŒåŒå­¦ç»è¿‡è¿‘åŠå¹´å‡†å¤‡ï¼Œå…±åŒå½¢æˆäº†è¿™ç¯‡43â»šçš„ç»¼è¿°å’Œè§‚ç‚¹â½‚ç«  Pre-Trained Models: Past, Present and Future |

1. # å¤§æ¨¡å‹ä¸å¤šæ¨¡æ€ç›¸å…³

| **ID** | **Paper**                                                    | **Introduction**                                             |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡     | [BEiT: BERT Pre-Training of Image Transformers](https://arxiv.org/pdf/2106.08254.pdf) |                                                              |
| 2âœ¡     | [BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers](https://arxiv.org/pdf/2208.06366.pdf) |                                                              |
| 3âœ¡     | [Image as a Foreign Language: BEIT Pretraining for All Vision and Vision-Language Tasks](https://arxiv.org/pdf/2208.10442.pdf) | è¿™æ˜¯é’ˆå¯¹è¯¥è®ºâ½‚çš„[è§£è¯»ä¹‹â¼€](https://www.msra.cn/zh-cn/news/features/beit-3)2022å¹´8â½‰ï¼Œå¾®è½¯æå‡ºçš„å¤šæ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹BEiT-3 |
| 4âœ¡     | [Language Is Not All You Need: Aligning Perception with Language Models](https://arxiv.org/pdf/2302.14045.pdf) | å¾®è½¯23å¹´3â½‰1â½‡å‘å¸ƒçš„å¤šæ¨¡æ€â¼¤è¯­â¾”æ¨¡å‹Kosmos-1çš„è®ºâ½‚           |
| 5âœ¡     | [PaLM-E: An Embodied Multimodal Language Model](https://palm-e.github.io/assets/palm-e.pdf) | https://palm-e.github.io/Googleäº23å¹´3â½‰6â½‡å‘å¸ƒçš„å…³äºå¤šæ¨¡æ€LLMï¼šPaLM-Eï¼Œå¯è®©èƒ½å¬æ‡‚â¼ˆç±»æŒ‡ä»¤ä¸”å…·å¤‡è§†è§‰èƒ½â¼’çš„æœºå™¨â¼ˆâ¼²æ´» |
| 6âœ¡     | [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models](https://arxiv.org/pdf/2303.04671.pdf) | Visual ChatGPT                                               |
| 7âœ¡     | [MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models](https://arxiv.org/pdf/2304.10592.pdf) | https://minigpt-4.github.io/https://github.com/Vision-CAIR/MiniGPT-4/tree/main |
| 8âœ¡     | [Flamingo: a visual language model for few-shot learning](https://arxiv.org/pdf/2204.14198.pdf) |                                                              |
| 9âœ¡     | [Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer](https://arxiv.org/pdf/2203.03466.pdf) |                                                              |
| 10âœ¡âœ¡   | [End-to-End Object Detection with Transformers](https://arxiv.org/pdf/2005.12872.pdf) | DETR by 2020å¹´5â½‰ï¼Œè¿™æ˜¯é’ˆå¯¹DETRçš„[è§£è¯»ä¹‹â¼€](https://www.bilibili.com/video/BV1GB4y1X72R/?spm_id_from=888.80997.embed_other.whitelist)ç›®æ ‡æ£€æµ‹ä»»åŠ¡æ¨¡å‹æ¼”åŒ–è·¯çº¿ï¼š[ä¸€æ–‡è¯»æ‡‚ç›®æ ‡æ£€æµ‹ï¼šR-CNNã€Fast R-CNNã€Faster R-CNNã€YOLOã€SSD](https://blog.csdn.net/v_july_v/article/details/80170182)2014 R-CNN2015 Fast R-CNNã€Faster R-CNN2016 YOLOã€SSD2017 Mask R-CNNã€YOLOv22018 YOLOv32019 CenterNet2020.6 DETRä»2020å¹´å¼€å§‹ï¼Œè¿›å…¥å¤šæ¨¡æ€ [ä»VAEã€æ‰©æ•£æ¨¡å‹DDPMã€DETRåˆ°ViT/MAE/Swin transformer](https://blog.csdn.net/v_JULY_v/article/details/130361959) |
| 11âœ¡âœ¡âœ¡  | [Denoising Diffusion Implicit Models](https://arxiv.org/pdf/2010.02502.pdf) | 2020.10â½‰ DDIM                                               |
| 12âœ¡âœ¡âœ¡  | [AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE](https://arxiv.org/pdf/2010.11929.pdf) | Vision Transformerï¼Œæœ¬æ–‡ä¸ºViTæ¨¡å‹è®ºæ–‡ï¼Œè¡¨ç¤ºå¯ä»¥å®Œå…¨æŠ›å¼ƒå·ç§¯æ€è·¯å¤„ç†CVä»»åŠ¡ï¼ŒåŒæ ·ä½¿ç”¨Transformeræ¥å®Œæˆï¼ŒCVå’ŒNLPæ®Šé€”åŒå½’ |
| 13âœ¡âœ¡âœ¡  | [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020.pdf) | CLIPç”±OpenAIåœ¨2021å¹´1â½‰å‘å¸ƒï¼Œè¶…â¼¤è§„æ¨¡æ¨¡å‹é¢„è®­ç»ƒæå–è§†è§‰ç‰¹å¾ï¼Œå›¾â½šå’Œâ½‚æœ¬ä¹‹é—´çš„å¯¹â½å­¦ä¹ (ç®€å•ç²—æš´ç†è§£å°±æ˜¯å‘å¾®åš/æœ‹å‹åœˆæ—¶ï¼Œâ¼ˆå–œæ¬¢å‘â¼€æ®µâ½‚å­—ç„¶åå†é…â¼€å¼ æˆ–â¼å¼ å›¾ï¼ŒCLIPä¾¿æ˜¯å­¦ä¹ è¿™ç§å¯¹åº”å…³ç³»)ã€‚[è§£è¯»ä¹‹ä¸€](https://www.bilibili.com/video/BV1SL4y1s7LQ/?vd_source=02a7bf3dbb14104d4c31a9017ba6bd89)https://github.com/openai/CLIP [CLIP: Connecting Text and Images](https://openai.com/research/clip)2021å¹´10â½‰ï¼ŒAccompliceå‘å¸ƒçš„disco diffusionï¼Œä¾¿æ˜¯ç¬¬â¼€ä¸ªç»“åˆCLIPæ¨¡å‹å’Œdiffusionæ¨¡å‹çš„AIå¼€æºç»˜ç”»â¼¯å…·ï¼Œå…¶å†…æ ¸ä¾¿æ˜¯é‡‡â½¤çš„CLIPå¼•å¯¼æ‰©æ•£æ¨¡å‹(CLIP-Guided diffusion model)ä¸”åç»­æœ‰å¾ˆå¤šåŸºäºCLIPçš„â¼€ç³»åˆ—æ”¹è¿›æ¨¡å‹ï¼Œâ½å¦‚[Lseg](http://bilibili.com/video/BV1FV4y1p7Lm/?spm_id_from=333.788.recommend_more_video.0&vd_source=02a7bf3dbb14104d4c31a9017ba6bd89)ã€[GroupViT](https://www.bilibili.com/video/BV1FV4y1p7Lm/?spm_id_from=333.788.recommend_more_video.0&vd_source=02a7bf3dbb14104d4c31a9017ba6bd89)ã€[ViLD](https://www.bilibili.com/video/BV1FV4y1p7Lm/?spm_id_from=333.788.recommend_more_video.0&vd_source=02a7bf3dbb14104d4c31a9017ba6bd89)ã€[GLIP](https://www.bilibili.com/video/BV1FV4y1p7Lm/?spm_id_from=333.788.recommend_more_video.0&vd_source=02a7bf3dbb14104d4c31a9017ba6bd89) |
| 14âœ¡âœ¡âœ¡âœ¡ | [Zero-Shot Text-to-Image Generation](https://arxiv.org/pdf/2102.12092.pdf) | DALLÂ·EåŸå§‹è®ºâ½‚                                               |
| 15âœ¡    | [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/pdf/2103.14030.pdf) | 3â½‰ Swin Transformer [è§£è¯»ä¹‹ä¸€](https://www.bilibili.com/video/BV13L4y1475U/?vd_source=0534c0954ddd3d4c4bd8113d31975f6a) |
| 16âœ¡    | [Swin Transformer V2: Scaling Up Capacity and Resolution](https://arxiv.org/pdf/2111.09883.pdf) | Swin Transformer V2 è§£è¯»ä¹‹ä¸€                                 |
| 17âœ¡    | [Auto-Encoding Variational Bayes](https://arxiv.org/pdf/1312.6114.pdf) | è‹å‰‘æ—å…³äºVAEçš„[è§£è¯»ä¹‹â¼€](https://kexue.fm/archives/5253)å¦å¤–â¼€ä¸ªä½œè€…ï¼š[åŸºäºè‹è¿™ä¸ªVAEçš„è§£è¯»å¯¹æ‰©æ•£æ¨¡å‹çš„ç†è§£](https://zhuanlan.zhihu.com/p/563543020) |
| 18âœ¡âœ¡   | [Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239.pdf) | 2020å¹´6â½‰æå‡ºDDPMï¼Œå³ä¼—â¼ˆâ¼ä¸­å¸¸è¯´çš„diffusion modelè¿™æ˜¯è‹å‰‘æ—[å…³äºDDPMçš„ç›¸å¯¹é€šä¿—çš„ç³»åˆ—è§£è¯»](https://kexue.fm/search/DDPM/1/)å¦â¼€ä»½è§£è¯»ï¼š[What are Diffusion Models?(è¯¥è§£è¯»çš„ä¸­â½‚ç¬”è®°)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#forward-diffusion-process) |
| 19âœ¡âœ¡   | [BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://arxiv.org/pdf/2201.12086.pdf) | 2022å¹´1â½‰ BLIPSalesforce                                     |
| 20âœ¡âœ¡   | [Hierarchical Text-Conditional Image Generation with CLIP Latents](https://arxiv.org/pdf/2204.06125.pdf) | 2022å¹´4â½‰ DALLÂ·E 2ï¼Œ[è§£è¯»ä¹‹ä¸€](https://www.bilibili.com/video/BV17r4y1u77B/?spm_id_from=333.788&vd_source=02a7bf3dbb14104d4c31a9017ba6bd89)é€šè¿‡CLIP + Diffusion modelsï¼Œè¾¾åˆ°â½‚æœ¬â½£æˆå›¾åƒæ–°â¾¼åº¦ |
| 21âœ¡âœ¡âœ¡âœ¡ | [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/pdf/2112.10752.pdf) | 2022å¹´8â½‰å‘å¸ƒçš„Stable DiffusionåŸºäºLatent Diffusion Modelsï¼Œä¸“â»”â½¤äºâ½‚å›¾â½£æˆä»»åŠ¡è¿™äº›æ˜¯ç›¸å…³è§£è¯»ï¼š[å›¾è§£stable diffusion(ç¿»è¯‘ç‰ˆä¹‹â¼€)](https://jalammar.github.io/illustrated-stable-diffusion/)ã€è¿™æ˜¯[å¦â¼€è§£è¯»](https://zhuanlan.zhihu.com/p/583124756)ï¼Œè¿™â¾¥æœ‰ç¯‡[AIç»˜ç”»å‘å±•å²](https://mp.weixin.qq.com/s?__biz=MzIxODUzNTg2MA==&mid=2247483967&idx=1&sn=0a78b6e69486de29b89272fa14392949&chksm=97e840e4a09fc9f2a99a482e5cc860c38d5b50d31cabbf190e21787dabcdf0d5894d161a1359&mpshare=1&scene=23&srcid=0312mEP6h7CabVqXw6DqLR4j&sharer_sharetime=1678633719409&sharer_shareid=8dff0e13d79dbe85e759d04101e63bbf#rd)çš„æ€»ç»“Stable Diffusionå’Œä¹‹å‰çš„Diffusionæ‰©æ•£åŒ–æ¨¡å‹ç›¸â½, é‡ç‚¹æ˜¯åšäº†â¼€ä»¶äº‹, é‚£å°±æ˜¯æŠŠæ¨¡å‹çš„è®¡ç®—ç©ºé—´ï¼Œä»åƒç´ ç©ºé—´ç»è¿‡æ•°å­¦å˜æ¢ï¼Œåœ¨å°½å¯èƒ½ä¿ç•™ç»†èŠ‚ä¿¡æ¯çš„æƒ…å†µä¸‹é™ç»´åˆ°â¼€ä¸ªç§°ä¹‹ä¸ºæ½œç©ºé—´(Latent Space)çš„ä½ç»´ç©ºé—´â¾¥ï¼Œç„¶åå†è¿›â¾ç¹é‡çš„æ¨¡å‹è®­ç»ƒå’Œå›¾åƒâ½£æˆè®¡ç®— |
| 22âœ¡âœ¡   | [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/pdf/2301.12597.pdf) | 2023å¹´1â½‰ BLIP2Salesforce                                    |
| 23âœ¡âœ¡   | [Aligning Text-to-Image Models using Human Feedback](https://arxiv.org/pdf/2302.12192.pdf) | ChatGPTçš„ä¸»è¦æˆåŠŸè¦å½’ç»“äºé‡‡â½¤RLHFæ¥ç²¾è°ƒLLMï¼Œè¿‘â½‡â¾•æ­ŒAIå›¢é˜Ÿå°†ç±»ä¼¼çš„æ€è·¯â½¤äºâ½‚â½£å›¾â¼¤æ¨¡å‹ï¼šåŸºäºâ¼ˆç±»åé¦ˆï¼ˆHuman Feedbackï¼‰æ¥ç²¾è°ƒStable Diffusionæ¨¡å‹æ¥æå‡â½£æˆæ•ˆæœâ½¬å‰çš„â½‚â½£å›¾æ¨¡å‹è™½ç„¶å·²ç»èƒ½å¤Ÿå–å¾—â½è¾ƒå¥½çš„å›¾åƒâ½£æˆæ•ˆæœï¼Œä½†æ˜¯å¾ˆå¤šæ—¶å€™å¾€å¾€éš¾ä»¥â½£æˆä¸è¾“â¼Šâ½‚æœ¬ç²¾ç¡®åŒ¹é…çš„å›¾åƒï¼Œç‰¹åˆ«æ˜¯åœ¨ç»„åˆå›¾åƒâ½£æˆâ½…â¾¯ã€‚ä¸ºæ­¤ï¼Œâ¾•æ­Œæœ€æ–°çš„è®ºâ½‚æå‡ºäº†åŸºäºâ¼ˆç±»åé¦ˆçš„ä¸‰æ­¥ç²¾è°ƒâ½…æ³•æ¥æ”¹å–„è¿™ä¸ªé—®é¢˜ |
| 24âœ¡âœ¡   | [InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning](https://arxiv.org/pdf/2305.06500v1.pdf) | 23å¹´5â½‰å‘å¸ƒçš„InstructBLIPè®ºâ½‚ï¼Œè¿™æ˜¯å…¶[è§£è¯»ä¹‹ä¸€](https://aijishu.com/a/1060000000403483) |
| 25âœ¡    | [LAVIS: A Library for Language-Vision Intelligence](https://arxiv.org/pdf/2209.09019.pdf) | Salesforceå¼€æºâ¼€ç«™å¼è§†è§‰è¯­â¾”å­¦ä¹ æ¡†æ¶LAVISï¼Œè¿™æ˜¯å…¶GitHubåœ°å€ï¼šhttps://github.com/salesforce/LAVIS |
| 26âœ¡    | [MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models](https://arxiv.org/pdf/2306.13394.pdf) | å¯¹å„ç§å¤šæ¨¡æ€æ¨¡å‹çš„è¯„æµ‹ï¼Œè¿™æ˜¯å…¶[è§£è¯»ä¹‹â¼€](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652347745&idx=3&sn=76b3a814bcc6ccb37406533ed0480b48&chksm=f124e990c6536086a799e24d957e5aa20af33d8aa83d8c826902c8cf3867fff0bb01a8ea5ac0&mpshare=1&scene=23&srcid=0712TK888nWW6AbQGmdGlLdz&sharer_sharetime=1689177014339&sharer_shareid=8dff0e13d79dbe85e759d04101e63bbf#rd) |
| 27âœ¡âœ¡âœ¡  | [Segment Anything](https://scontent-hkg4-1.xx.fbcdn.net/v/t39.2365-6/10000000_900554171201033_1602411987825904100_n.pdf?_nc_cat=100&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=mmvtlZMA04wAX-RwgTa&_nc_ht=scontent-hkg4-1.xx&oh=00_AfBuHxlkg_suWaHlbfcxnHKk3OlAF2H70izO36Hx3wlHhg&oe=64E10CA7) | 23å¹´4.6â½‡ï¼ŒMetaå‘å¸ƒå²ä¸Šâ¾¸ä¸ªå›¾åƒåˆ†å‰²åŸºç¡€æ¨¡å‹SAMï¼Œå°†NLPé¢†åŸŸçš„promptèŒƒå¼å¼•è¿›CVï¼Œè®©æ¨¡å‹å¯ä»¥é€šè¿‡promptâ¼€é”®æŠ å›¾ |
| 28âœ¡    | [A Comprehensive Survey on Segment Anything Model for Vision and Beyond](https://arxiv.org/pdf/2305.08196.pdf) | å¯¹åˆ†å‰²â¼€åˆ‡æ¨¡å‹SAMçš„â¾¸ç¯‡å…¨â¾¯ç»¼è¿°ï¼š28â»šã€200+ç¯‡å‚è€ƒâ½‚çŒ®ï¼Œè¿™æ˜¯å…¶[ä¸­â½‚ä»‹ç»é“¾æ¥](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650877786&idx=2&sn=7264a23e74fc81daaac7fae0de247941&chksm=84e4eb24b39362325b30d718124cca7c70325f9cdd771fbc1166d300d2a767177d11cb691462&mpshare=1&scene=23&srcid=0522z3SBExD0DdKqKoXQL8R2&sharer_sharetime=1684766416477&sharer_shareid=8dff0e13d79dbe85e759d04101e63bbf%23rd) |
| 29âœ¡    | [Fast Segment Anything](https://arxiv.org/pdf/2306.12156.pdf) | ä¸­ç§‘é™¢ç‰ˆçš„åˆ†å‰²â¼€åˆ‡ï¼Œè¿™æ˜¯[FastSAMçš„è§£è¯»ä¹‹â¼€](https://www.36kr.com/p/2319699358433664) |
| 30âœ¡    | [FASTER SEGMENT ANYTHING: TOWARDS LIGHTWEIGHT SAM FOR MOBILE APPLICATIONS](https://arxiv.org/pdf/2306.14289.pdf) | â½SAMâ¼©60å€ï¼Œâ½FastSAMå¿«4å€ï¼Œé€Ÿåº¦å’Œæ•ˆæœåŒèµ¢                  |

1. # ç±»ChatGPTåŠå‚åŸŸç‰ˆç±»ChatGPTå¼€æºæ¨¡å‹

| **ID**  | **Paper**                                                    | **Introduction**                                             |
| ------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1âœ¡âœ¡     | **LaMDA**: [Language Models for Dialog Applications](https://arxiv.org/pdf/2201.08239) | Google LaMDAæ¨¡å‹ï¼Œå‚æ•°137Bï¼Œtransformer decoderæ¶æ„ï¼Œè¿™æ˜¯[ç®€è¦è§£è¯»ä¹‹â¼€](https://zhuanlan.zhihu.com/p/573654291)åœ¨å¾®è°ƒé˜¶æ®µ ä½¿â½¤58Kçš„å¯¹è¯æ•°æ®ï¼Œè¿‡ç¨‹ç±»ä¼¼çœŸâ¼ˆçš„å¯¹è¯è¿‡ç¨‹ï¼Œç»™å®šâ¼€ä¸ªQueryï¼Œâ½å¦‚ How old is Rafael Nadal? ï¼Œå¦‚æœâ¼ˆçŸ¥é“ç­”æ¡ˆï¼Œé‚£ä¹ˆç›´æ¥å›ç­”35å²å³å¯ï¼Œå¦‚æœä¸çŸ¥é“ï¼Œåˆ™éœ€è¦å» Research â¼€ä¸‹ï¼Œå€ŸåŠ©æœç´¢å¼•æ“æ‰¾åˆ°ç­”æ¡ˆï¼Œç„¶åå†å›ç­”35å²**ChatGPT****çš„æ›¿ä»£æ–¹æ¡ˆ** |
| 2âœ¡      | [PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/pdf/2204.02311) | 22å¹´3â½‰ï¼ŒGoogleçš„Barhamç­‰â¼ˆå‘å¸ƒäº†Pathwaysç³»ç»Ÿï¼Œâ½¤äºæ›´â¾¼æ•ˆåœ°è®­ç»ƒâ¼¤å‹æ¨¡å‹ï¼›Pathways çš„æ„¿æ™¯æ˜¯å®ç°â¼€ä¸ªå¾ˆæ¥è¿‘â¼ˆè„‘çš„æ¡†æ¶ï¼šâ¼€ä¸ªæ¨¡å‹ï¼Œå¯ä»¥åšå¤šä»»åŠ¡ï¼Œå¤šæ¨¡æ€ä¸”åœ¨åšä»»åŠ¡æ—¶ï¼Œåªæ˜¯ sparsely activatedï¼Œåªä½¿â½¤â¼€éƒ¨åˆ†çš„å‚æ•°22å¹´4â½‰ï¼ŒGoogleå‘å¸ƒPaLMæ¨¡å‹ï¼ŒåŸºäºTransformer decoderæ¶æ„ï¼Œå‚æ•°è§„æ¨¡è¾¾540Bï¼Œä½¿â½¤multi-queryæ³¨æ„â¼’ã€SwiGLUæ¿€æ´»å‡½æ•°ä»¥åŠRoPEä½ç½®åµŒâ¼Šï¼Œè¿™æ˜¯[ç¿»è¯‘ä¹‹â¼€](https://zhuanlan.zhihu.com/p/503968575)PaLMâ¾¸æ¬¡å±•ç¤ºäº†Pathwaysçš„â¼¤è§„æ¨¡ä½¿â½¤â€”â€”èƒ½å¤Ÿä»¥â¾¼æ•ˆçš„â½…å¼åœ¨æ•°åƒæˆ–æ•°ä¸‡ä¸ªåŠ é€Ÿå™¨èŠ¯â½šä¸Šè®­ç»ƒâ¼€ä¸ªæ¨¡å‹ |
| 3âœ¡      | [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/pdf/2212.08073) | ChatGPTçš„ç«å“ï¼ŒChatGPTâ½¤â¼ˆç±»åå¥½è®­ç»ƒRMå†RL(å³RLHF)ï¼ŒClaudeåˆ™åŸºäºAIåå¥½æ¨¡å‹è®­ç»ƒRMå†RL(å³RLAIF) ï¼Œç ”ç©¶äººå‘˜å°†å¯¹é½æ€æƒ³æ›´è¿›ä¸€æ­¥ï¼Œæå‡ºäº†ä¸€ç§åˆ›å»ºæ— å®³AIç³»ç»Ÿçš„è®­ç»ƒæœºåˆ¶ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè§„åˆ™åˆ—è¡¨ï¼ˆç”±äººç±»æä¾›ï¼‰çš„è‡ªè®­ç»ƒæœºåˆ¶ï¼Œè€Œéäººç±»ç›‘ç£ã€‚ä»æŠ€æœ¯ä¸Šæ¥è¯´ï¼ŒConsitutinal AIä½¿ç”¨çš„æ˜¯AIåé¦ˆè€Œéäººç±»åé¦ˆã€‚ |
| 4âœ¡      | [Improving alignment of dialogue agents via targeted human judgements](https://arxiv.org/pdf/2209.14375) | DeepMindçš„Sparrowï¼Œè¿™ä¸ªâ¼¯ä½œå‘è¡¨æ—¶é—´ç¨æ™šäºinstructGPTï¼Œå…¶â¼¤è‡´çš„æŠ€æœ¯æ€è·¯å’Œæ¡†æ¶ä¸ instructGPT çš„ä¸‰é˜¶æ®µåŸºæœ¬ç±»ä¼¼ï¼Œä½†Sparrow ä¸­æŠŠå¥–åŠ±æ¨¡å‹åˆ†ä¸ºä¸¤ä¸ªä¸åŒ RM çš„æ€è·¯**ChatGPT****çš„æ›¿ä»£æ–¹æ¡ˆ** |
| 5âœ¡      | [Crosslingual Generalization through Multitask Finetuning](https://arxiv.org/pdf/2211.01786.pdf) | **ChatGPT****çš„æ›¿ä»£æ–¹æ¡ˆ**                                    |
| 6âœ¡      | [LLaMA: Open and Efficient Foundation Language Models](https://scontent-hkg4-1.xx.fbcdn.net/v/t39.8562-6/333078981_693988129081760_4712707815225756708_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=iVbwJKA_j4MAX-6b3k4&_nc_ht=scontent-hkg4-1.xx&oh=00_AfCWx7Ip8eypOwJrdtL-cD4lezDdlN8TbWQnXmz8YeAn4w&oe=64E14022) | 2023å¹´2â½‰24â½‡Metaå‘å¸ƒäº†å…¨æ–°çš„65Bå‚æ•°â¼¤è¯­â¾”æ¨¡å‹LLaMAï¼Œå¼€æºï¼Œâ¼¤éƒ¨åˆ†ä»»åŠ¡çš„æ•ˆæœå¥½äº2020å¹´çš„GPT-3 |
| 7âœ¡âœ¡âœ¡    | [Alpaca: A Strong Open-Source Instruction-Following Model](https://crfm.stanford.edu/2023/03/13/alpaca.html) | alpacaè®ºæ–‡https://github.com/tatsu-lab/stanford_alpaca       |
| 8âœ¡âœ¡âœ¡    | [Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality](https://lmsys.org/blog/2023-03-30-vicuna/) | Vicunaè®ºæ–‡                                                   |
| 9âœ¡âœ¡âœ¡    | [GLM: General Language Model Pretraining with Autoregressive Blank Infilling](https://arxiv.org/pdf/2103.10360.pdf) | https://zhuanlan.zhihu.com/p/6294619542022å¹´5â½‰ï¼Œæ­£å¼æå‡ºäº†GLMæ¡†æ¶ |
| 10âœ¡âœ¡âœ¡   | [GLM-130B: AN OPEN BILINGUAL PRE-TRAINED MODEL](https://arxiv.org/pdf/2210.02414.pdf) | GLM-130Bä¾¿æ˜¯åŸºäºçš„GLMæ¡†æ¶çš„â¼¤è¯­â¾”æ¨¡å‹                        |
| 11âœ¡âœ¡âœ¡âœ¡âœ¡ | [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)            | ChatGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº [General Language Model (GLM)](https://github.com/THUDM/GLM) æ¶æ„ï¼Œå…·æœ‰ 62 äº¿å‚æ•°ã€‚ç»“åˆæ¨¡å‹é‡åŒ–æŠ€æœ¯ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ¶ˆè´¹çº§çš„æ˜¾å¡ä¸Šè¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼ˆINT4 é‡åŒ–çº§åˆ«ä¸‹æœ€ä½åªéœ€ 6GB æ˜¾å­˜ï¼‰ã€‚ ChatGLM-6B ä½¿ç”¨äº†å’Œ ChatGPT ç›¸ä¼¼çš„æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸­æ–‡é—®ç­”å’Œå¯¹è¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚ç»è¿‡çº¦ 1T æ ‡è¯†ç¬¦çš„ä¸­è‹±åŒè¯­è®­ç»ƒï¼Œè¾…ä»¥ç›‘ç£å¾®è°ƒã€åé¦ˆè‡ªåŠ©ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯çš„åŠ æŒï¼Œ62 äº¿å‚æ•°çš„ ChatGLM-6B å·²ç»èƒ½ç”Ÿæˆç›¸å½“ç¬¦åˆäººç±»åå¥½çš„å›ç­”ï¼Œæ›´å¤šä¿¡æ¯è¯·å‚è€ƒæˆ‘ä»¬çš„[åšå®¢](https://chatglm.cn/blog)ã€‚æ¬¢è¿é€šè¿‡ [chatglm.cn](https://chatglm.cn/) ä½“éªŒæ›´å¤§è§„æ¨¡çš„ ChatGLM æ¨¡å‹ã€‚ |
| 12âœ¡     | [Opt: Open pre-trained transformer language models](https://arxiv.org/pdf/2205.01068.pdf) | GPTå¼€æºå¹³æ›¿                                                  |
| 13âœ¡     | [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/pdf/2211.05100.pdf) | GPTå¼€æºå¹³æ›¿                                                  |
| 14âœ¡     | [UL2: Unifying Language Learning Paradigms](https://arxiv.org/pdf/2205.05131.pdf) | GPTå¼€æºå¹³æ›¿                                                  |
| 15âœ¡     | [Large Language Models Encode Clinical Knowledge](https://arxiv.org/pdf/2212.13138.pdf) | ä»palm - flan palm(æŒ‡ä»¤å¾®è°ƒpalmæ¨¡å‹) - instruction prompt-tuned Flan-PaLM(æç¤ºæŒ‡ä»¤è°ƒä¼˜flan-palmæ¨¡å‹)çš„è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡instruction prompt-tuned Flan-PaLMå¾—åˆ°åŒ»ç–—é—®ç­”æ¨¡å‹med-palmï¼Œâ½½æå‡ºäº†instruction prompt tuning |
| 16âœ¡     | [Towards Expert-Level Medical Question Answering with Large Language Models](https://arxiv.org/pdf/2305.09617.pdf) | ç»§ä¸Šç¯‡è®ºâ½‚æå‡ºmedpalmä¹‹åï¼Œ5â½‰16â½‡ï¼ŒGoogle Researchå’ŒDeepMindå‘å¸ƒäº†Med-PaLM 2ï¼Œç›¸â½ç¬¬â¼€ä»£æœ€æ˜¾è‘—çš„æ”¹è¿›æ˜¯åŸºåº§æ¨¡å‹æ¢æˆäº†Googleçš„æœ€æ–°â¼¤æ¨¡å‹PaLM2(æ®è¯´æœ‰ç€340bå‚æ•°ï¼Œâ½¤äºè®­ç»ƒçš„tokenæ•°è¾¾3.6ä¸‡äº¿) |
| 17âœ¡     | [ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge](https://arxiv.org/pdf/2303.14070.pdf) | åŒ»ç–—ChatDoctorè®ºâ½‚                                           |
| 18âœ¡âœ¡    | [BloombergGPT: A Large Language Model for Finance](https://arxiv.org/pdf/2303.17564.pdf) | â¾¦èBloombergGPTè®ºâ½‚ï¼Œè¿™æ˜¯å…¶[è§£è¯»ä¹‹â¼€](https://zhuanlan.zhihu.com/p/619444812) |
| 19âœ¡     | [COLT5: Faster Long-Range Transformers with Conditional Computation](https://arxiv.org/pdf/2303.09752.pdf) |                                                              |
| 20âœ¡     | [ProtTransï¼šTowards Cracking the Language of Lifeâ€™s Code Through Self-Supervised Deep Learning and High Performance Computing](https://arxiv.org/pdf/2007.06225.pdf) |                                                              |
| 21âœ¡     | [Highly accurate protein structure prediction with AlphaFold](https://www.nature.com/articles/s41586-021-03819-2) |                                                              |
| 22âœ¡     | [Large Language Models Generate Functional Protein Sequences Across Diverse Families](https://www.nature.com/articles/s41587-022-01618-2) |                                                              |
| 23âœ¡     | [Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling](https://arxiv.org/pdf/2304.01373.pdf) | Pythiaæ˜¯ä¸€ç»„å¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå‚æ•°é‡ä»7åƒä¸‡åˆ°120äº¿ä¸ç­‰ï¼Œä»¥ç”¨äºç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¼”å˜æ¨¡å‹æ¶æ„ç±»ä¼¼äºGPT-3ï¼Œä½†åŒ…æ‹¬ä¸€äº›ç»„ä»¶æ”¹è¿›ï¼Œä¾‹å¦‚ç”¨Flash Attentionå’ŒRotary Positional Embeddingsã€‚Pythiaç ”ç©¶çš„ä¸»è¦ç»“è®ºå¦‚ä¸‹ï¼šåœ¨é‡å¤æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼ˆè¶…è¿‡1ä¸ªepochï¼‰ä¸ä¼šæå‡æˆ–é™ä½æ€§èƒ½ã€‚è®­ç»ƒé¡ºåºä¸ä¼šå½±å“è®°å¿†ã€‚è¿™ä¸ªç»“è®ºè®©æˆ‘ä»¬æ— æ³•é€šè¿‡é‡æ–°æ’åºè®­ç»ƒæ•°æ®æ¥ç¼“è§£ä¸å¸Œæœ›çš„é€å­—è®°å¿†é—®é¢˜ã€‚é¢„è®­ç»ƒè¯é¢‘å½±å“ä»»åŠ¡æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œå¯¹äºæ›´é¢‘ç¹çš„æœ¯è¯­ï¼Œå°‘æ ·æœ¬å­¦ä¹ å¾€å¾€å‡†ç¡®åº¦æ›´é«˜ã€‚å°†batch sizeåŠ å€å¯ä»¥å°†è®­ç»ƒæ—¶é—´å‡åŠï¼Œä½†ä¸ä¼šå½±å“æ”¶æ•›ã€‚ |